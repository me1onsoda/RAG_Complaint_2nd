import pandas as pd
import os
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from tqdm import tqdm

# ==========================================
# 1. ì„¤ì • (ê²½ë¡œ ë° ëª¨ë¸)
# ==========================================

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ
JOJIK_FILES = [
    "./data/jojik_data/jojik_gangnam_list.csv",
    "./data/jojik_data/jojik_mapo_list.csv",
    "./data/jojik_data/jojik_nowon_list.csv" # íŒŒì¼ëª…ì— .csvê°€ ë‘ ë²ˆ ë“¤ì–´ê°„ ê²ƒ ì£¼ì˜
]
LAW_FILE = "./data/processed/law_database_refined.csv"

# ë²¡í„° DB ì €ì¥ ê²½ë¡œ (ì´ í´ë”ì— AIì˜ ì§€ëŠ¥ì´ ì €ì¥ë©ë‹ˆë‹¤)
DB_PATH = "./chroma_db"

# ì„ë² ë”© ëª¨ë¸ (í•œê¸€ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ì‚¬ìš©)
# jhgan/ko-sroberta-multitask ëª¨ë¸ì´ ë¯¼ì›/ë²•ë ¹ ê²€ìƒ‰ì— ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤.
MODEL_NAME = "jhgan/ko-sroberta-multitask"

def load_jojik_data():
    """
    í©ì–´ì ¸ ìˆëŠ” ì¡°ì§ë„ CSVë“¤ì„ ì½ì–´ì„œ í‘œì¤€í™”ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
    """
    documents = []
    print("ğŸ¢ ì¡°ì§ë„ ë°ì´í„° ë¡œë”© ë° ë³€í™˜ ì¤‘...")

    for file_path in JOJIK_FILES:
        if not os.path.exists(file_path):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
            continue

        try:
            df = pd.read_csv(file_path)
            # êµ¬ì²­ ì´ë¦„ ì¶”ì¸¡ (íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
            gu_name = os.path.basename(file_path).split('_')[1] 

            for _, row in df.iterrows():
                # êµ¬ì²­ë§ˆë‹¤ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥´ë¯€ë¡œ í†µì¼ ì‘ì—… í•„ìš”
                # 1. ë¶€ì„œëª…/íŒ€ëª… í•©ì¹˜ê¸°
                dept_info = ""
                if 'ë¶€ì„œëª…' in df.columns: dept_info += str(row['ë¶€ì„œëª…']) + " "
                if 'ì†Œì†' in df.columns: dept_info += str(row['ì†Œì†']) + " "
                if 'íŒ€ëª…' in df.columns: dept_info += str(row['íŒ€ëª…']) + " "
                if 'ëŒ€ë¶„ë¥˜(êµ­/ê³¼)' in df.columns: dept_info += str(row['ëŒ€ë¶„ë¥˜(êµ­/ê³¼)']) + " "
                
                # 2. ë‹´ë‹¹ì—…ë¬´ (ê°€ì¥ ì¤‘ìš”!)
                job_desc = str(row['ë‹´ë‹¹ì—…ë¬´']) if 'ë‹´ë‹¹ì—…ë¬´' in df.columns else ""
                
                # 3. ì „í™”ë²ˆí˜¸
                phone = str(row['ì „í™”ë²ˆí˜¸']) if 'ì „í™”ë²ˆí˜¸' in df.columns else ""

                # 4. AIì—ê²Œ í•™ìŠµì‹œí‚¬ í…ìŠ¤íŠ¸ ë‚´ìš© êµ¬ì„±
                # ì˜ˆ: "ê°•ë‚¨êµ¬ ì£¼íƒê³¼ ì£¼íƒíŒ€. ë‹´ë‹¹ì—…ë¬´: ì•„íŒŒíŠ¸ ê´€ë¦¬, ë¯¼ì› ì²˜ë¦¬."
                content = f"{gu_name} {dept_info.strip()}. ë‹´ë‹¹ì—…ë¬´: {job_desc}"
                
                # 5. ë©”íƒ€ë°ì´í„° (ë‚˜ì¤‘ì— ì¶œì²˜ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•¨)
                metadata = {
                    "category": "organization", # ì¡°ì§ë„ ì¹´í…Œê³ ë¦¬
                    "source": gu_name,
                    "dept": dept_info.strip(),
                    "phone": phone
                }

                # ë¬¸ì„œ ê°ì²´ ìƒì„±
                doc = Document(page_content=content, metadata=metadata)
                documents.append(doc)

        except Exception as e:
            print(f"âŒ {file_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    print(f"âœ… ì¡°ì§ë„ ë¬¸ì„œ {len(documents)}ê°œ ë³€í™˜ ì™„ë£Œ.")
    return documents

def load_law_data():
    """
    ë²•ë ¹ ë°ì´í„°ë¥¼ ì½ì–´ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
    """
    documents = []
    print("\nâš–ï¸ ë²•ë ¹ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    if not os.path.exists(LAW_FILE):
        print(f"âŒ ë²•ë ¹ íŒŒì¼ ì—†ìŒ: {LAW_FILE}")
        return []

    try:
        df = pd.read_csv(LAW_FILE)
        
        for _, row in df.iterrows():
            content = str(row['ë‚´ìš©'])
            
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "category": "law", # ë²•ë ¹ ì¹´í…Œê³ ë¦¬
                "source_id": str(row['source_id'])
            }
            
            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)
            
    except Exception as e:
        print(f"âŒ ë²•ë ¹ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    print(f"âœ… ë²•ë ¹ ë¬¸ì„œ {len(documents)}ê°œ ë³€í™˜ ì™„ë£Œ.")
    return documents

def main():
    # 1. ë°ì´í„° ì¤€ë¹„
    jojik_docs = load_jojik_data()
    law_docs = load_law_data()
    
    all_docs = jojik_docs + law_docs
    
    if not all_docs:
        print("âŒ ë³€í™˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    print(f"\nğŸš€ ì´ {len(all_docs)}ê°œì˜ ë¬¸ì„œë¥¼ ë²¡í„°í™”(ì„ë² ë”©) ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ì‚¬ìš© ëª¨ë¸: {MODEL_NAME}")
    print("ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

    # 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embeddings = HuggingFaceEmbeddings(
        model_name=MODEL_NAME,
        model_kwargs={'device': 'cpu'}, # GPUê°€ ìˆë‹¤ë©´ 'cuda'ë¡œ ë³€ê²½
        encode_kwargs={'normalize_embeddings': True}
    )

    # 3. ë²¡í„° DB ìƒì„± ë° ì €ì¥
    # ê¸°ì¡´ DBê°€ ìˆë‹¤ë©´ ë¡œë“œí•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
    vector_store = Chroma.from_documents(
        documents=all_docs,
        embedding=embeddings,
        persist_directory=DB_PATH
    )

    print("-" * 50)
    print(f"ğŸ‰ ë²¡í„°í™” ì™„ë£Œ! ë°ì´í„°ë² ì´ìŠ¤ê°€ '{DB_PATH}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ì´ì œ AIê°€ ì´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()