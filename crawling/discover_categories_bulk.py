import os
import glob
import pandas as pd
import random
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate

# ======================================================
# [ì„¤ì •] ë°ì´í„°ê°€ ëª¨ì—¬ìˆëŠ” í´ë” ê²½ë¡œ
# ======================================================
DATA_DIR = "data/processed_data"  # ì‚¬ìš©ìì˜ ì‹¤ì œ ê²½ë¡œ
FILE_PATTERN = "*_cleaned.csv"    # ëì´ _cleaned.csvë¡œ ëë‚˜ëŠ” ëª¨ë“  íŒŒì¼

# 1. AI ì¤€ë¹„
print("ğŸ¤– Llamaë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
llm = ChatOllama(model="llama3.1", temperature=0)

def load_and_analyze_all():
    # 1. íŒŒì¼ ëª©ë¡ ì°¾ê¸°
    # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì¡°í•©
    current_dir = os.path.dirname(os.path.abspath(__file__))
    search_path = os.path.join(current_dir, DATA_DIR, FILE_PATTERN)
    
    file_list = glob.glob(search_path)
    
    if not file_list:
        print(f"âŒ íŒŒì¼ì„ í•˜ë‚˜ë„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤! ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {search_path}")
        return

    print(f"ğŸ“‚ ì´ {len(file_list)}ê°œì˜ êµ¬ì²­ ë°ì´í„° íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
    
    all_samples = []
    
    # 2. ê° íŒŒì¼ì—ì„œ ë°ì´í„° ê³¨ê³ ë£¨ ë½‘ê¸°
    for file_path in file_list:
        try:
            # CSV íŒŒì¼ ì½ê¸°
            df = pd.read_csv(file_path)
            
            # [ì¤‘ìš”] ë¯¼ì› ë‚´ìš©ì´ ë‹´ê¸´ ì»¬ëŸ¼(ì—´) ì´ë¦„ ì°¾ê¸°
            # ë³´í†µ 'ë‚´ìš©', 'content', 'ë¯¼ì›ë‚´ìš©' ë“±ì˜ ì´ë¦„ì¼ ê²ƒì…ë‹ˆë‹¤.
            # ìë™ìœ¼ë¡œ ì°¾ê¸° ìœ„í•´ ì»¬ëŸ¼ëª…ë“¤ì„ í›‘ì–´ë´…ë‹ˆë‹¤.
            text_col = None
            for col in df.columns:
                if "ë‚´ìš©" in col or "ì œëª©" in col or "content" in col or "complaint" in col:
                    text_col = col
                    break
            
            if text_col:
                # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ê° êµ¬ì²­ë§ˆë‹¤ 5ê°œì”©ë§Œ ëœë¤ìœ¼ë¡œ ë½‘ê¸° (AI ë©”ëª¨ë¦¬ ìš©ëŸ‰ ê³ ë ¤)
                # ë°ì´í„°ê°€ ì ìœ¼ë©´ ìˆëŠ” ë§Œí¼ ë‹¤ ê°€ì ¸ì˜¤ê¸°
                n_samples = min(len(df), 15) 
                sampled_texts = df[text_col].dropna().sample(n=n_samples).tolist()
                
                # "ê°•ë‚¨êµ¬: ë¶ˆë²•ì£¼ì°¨ê°€ ì‹¬ê°í•´ìš”" í˜•íƒœë¡œ ì¶œì²˜ë¥¼ ë¶™ì—¬ì¤Œ
                file_name = os.path.basename(file_path)
                all_samples.extend([f"[{file_name}] {text[:100]}" for text in sampled_texts])
                print(f"  - {file_name}: {n_samples}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            else:
                print(f"  âš ï¸ {os.path.basename(file_path)}: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ëª» ì°¾ì•„ì„œ ê±´ë„ˆëœë‹ˆë‹¤. (ì»¬ëŸ¼ëª…: {df.columns})")
                
        except Exception as e:
            print(f"  âŒ {os.path.basename(file_path)} ì½ê¸° ì‹¤íŒ¨: {e}")

    print(f"\nâœ… ì´ {len(all_samples)}ê°œì˜ ë‹¤ì–‘í•œ ë¯¼ì› ìƒ˜í”Œì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤!")
    print("â³ AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ êµ¬ìƒ ì¤‘ì…ë‹ˆë‹¤... (1ë¶„ ì •ë„ ì†Œìš”)")

    # 3. AIì—ê²Œ ë¶„ì„ ìš”ì²­
    # ìƒ˜í”Œë“¤ì„ í•˜ë‚˜ì˜ ê¸´ ê¸€(ë¬¸ìì—´)ë¡œ í•©ì¹¨
    combined_text = "\n".join(all_samples)
    
    template = """
    ë„ˆëŠ” [ê³µê³µ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€]ì•¼.
    ì„œìš¸ì‹œ ì—¬ëŸ¬ êµ¬ì²­ì—ì„œ ìˆ˜ì§‘ëœ ì•„ë˜ [ë¯¼ì› ë°ì´í„° ìƒ˜í”Œ]ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì¤˜.
    
    ì´ ë¯¼ì›ë“¤ì„ ë¶„ë¥˜í•  ë•Œ, 'ê¸°íƒ€' ì¹´í…Œê³ ë¦¬ê°€ ìµœëŒ€í•œ ë‚˜ì˜¤ì§€ ì•Šë„ë¡ 
    ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë°œìƒí•˜ê³  ëª…í™•í•˜ê²Œ êµ¬ë¶„ë˜ëŠ” [í•µì‹¬ ì¹´í…Œê³ ë¦¬ 10~15ê°œ]ë¥¼ ì„ ì •í•´ì¤˜.
    
    [ì¶œë ¥ í˜•ì‹]
    - ì¹´í…Œê³ ë¦¬ëª… (ì„¤ëª… ë° í¬í•¨ë˜ëŠ” ì˜ˆì‹œ ë¯¼ì› í‚¤ì›Œë“œ)
    - ì¹´í…Œê³ ë¦¬ëª… (ì„¤ëª… ë° í¬í•¨ë˜ëŠ” ì˜ˆì‹œ ë¯¼ì› í‚¤ì›Œë“œ)
    ...
    
    [ë¶„ì„í•  ë¯¼ì› ë°ì´í„° ìƒ˜í”Œ ëª¨ìŒ]
    {text}
    """
    
    prompt = ChatPromptTemplate.from_template(template)
    chain = prompt | llm
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ë©´ AIê°€ ì˜¤ë¥˜ë¥¼ ë‚¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ 3000ì ì •ë„ë¡œ ìë¦„
    if len(combined_text) > 30000:
        combined_text = combined_text[:30000] + "...(ìƒëµ)..."

    response = chain.invoke({"text": combined_text})
    
    print("\n" + "="*50)
    print("ğŸ† AIê°€ ì œì•ˆí•˜ëŠ” [ì„œìš¸ì‹œ í†µí•© ë¯¼ì› ì¹´í…Œê³ ë¦¬]")
    print("="*50)
    print(response.content)

if __name__ == "__main__":
    load_and_analyze_all()