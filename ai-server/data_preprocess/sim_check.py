import psycopg2
from psycopg2.extras import RealDictCursor
import requests

# DB ë° Ollama ì„¤ì •
DB_CONFIG = {
    "host": "localhost",
    "database": "postgres",
    "user": "postgres",
    "password": "sanghpw",
    "port": 5432
}
OLLAMA_URL = "http://localhost:11434/api/embeddings"
EMBED_MODEL = "mxbai-embed-large"

def get_embedding(text):
    """
    mxbai-embed-large ëª¨ë¸ì€ ê²€ìƒ‰ ì‹œ 'query: ' ì ‘ë‘ì‚¬ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.
    ì´ê²Œ ì—†ìœ¼ë©´ DBì— ì €ì¥ëœ 'doc: ' ë²¡í„°ì™€ ê±°ë¦¬ ì°¨ì´ê°€ í¬ê²Œ ë°œìƒí•©ë‹ˆë‹¤.
    """
    payload = {"model": EMBED_MODEL, "prompt": f"query: {text}"}
    try:
        res = requests.post(OLLAMA_URL, json=payload).json()
        return res.get('embedding')
    except Exception as e:
        print(f"Embedding Error: {e}")
        return None

def search_similar_complaints(input_text, top_k=5):
    # 1. ì…ë ¥ ë¯¼ì› ì„ë² ë”© ìƒì„± (mxbai ê¶Œì¥ query: ì ‘ë‘ì‚¬ ì‚¬ìš©)
    query_vec = get_embedding(input_text)
    if not query_vec:
        return

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    try:
        # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬
        # (1 - (embedding <=> %s::vector)) : ë²¡í„° ìœ ì‚¬ë„
        # ts_rank(search_vector, plainto_tsquery('simple', %s)) : í‚¤ì›Œë“œ ì¼ì¹˜ë„
        
        search_sql = """
        SELECT 
            id, 
            resp_dept, 
            core_request, 
            (1 - (embedding <=> %s::vector)) AS v_score,
            ts_rank(search_vector, plainto_tsquery('simple', %s)) AS k_score
        FROM complaint_normalizations
        ORDER BY ( (1 - (embedding <=> %s::vector)) * 0.7 + 
                   ts_rank(search_vector, plainto_tsquery('simple', %s)) * 0.3 ) DESC
        LIMIT %s;
        """
        
        # %sê°€ ì´ 5ê°œì…ë‹ˆë‹¤ (v_scoreìš© 1ê°œ, k_scoreìš© 1ê°œ, ORDER BYìš© 2ê°œ, LIMITìš© 1ê°œ)
        # í•˜ì§€ë§Œ ì¤‘ë³µ ì…ë ¥ì„ ì¤„ì´ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ ì¸ìë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        cur.execute(search_sql, (
            query_vec,    # v_score ê³„ì‚°ìš©
            input_text,   # k_score ê³„ì‚°ìš©
            query_vec,    # ORDER BY ë²¡í„° ì •ë ¬ìš©
            input_text,   # ORDER BY í‚¤ì›Œë“œ ì •ë ¬ìš©
            top_k         # LIMITìš©
        ))
        
        results = cur.fetchall()
        
        print(f"\n" + "="*60)
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ (Vector 70% + Keyword 30%)")
        print("="*60)

        for i, row in enumerate(results, 1):
            # ë‘ ì ìˆ˜ë¥¼ í•©ì¹œ ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            final_score = (float(row['v_score']) * 0.7) + (float(row['k_score']) * 0.3)
            
            print(f"[{i}] í†µí•© ì ìˆ˜: {final_score:.4f} (V: {row['v_score']:.3f}, K: {row['k_score']:.3f})")
            print(f"    - ë‹´ë‹¹ ë¶€ì„œ: {row['resp_dept']}")
            print(f"    - í•µì‹¬ ìš”ì•½: {row['core_request']}")
            print("-" * 60)

    except Exception as e:
        print(f"Search Error: {e}")
    finally:
        cur.close()
        conn.close()

if __name__ == "__main__":
    # ì‹¤ì œ í…ŒìŠ¤íŠ¸í•  ë¯¼ì› (1ì°¨ ëª¨ë¸ì´ ìš”ì•½í•œ í˜•íƒœë¼ê³  ê°€ì •)
    new_complaint = "['ì‘ë¬¼ ê¸ˆì§€', 'ê³µê³µí…ƒë°­', 'ë³´ë³µì„± ì–¸í–‰', 'ê´€ë¦¬ì êµìœ¡', 'ë¯¼ì› ì²˜ë¦¬']"
    
    search_similar_complaints(new_complaint)