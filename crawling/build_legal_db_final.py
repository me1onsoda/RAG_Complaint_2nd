import pandas as pd
import os
import random
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_core.documents import Document
from tqdm import tqdm

# [ì„¤ì •]
CSV_PATH = "data/processed/law_database_refined.csv"
DB_PATH = "legal_vector_db"
TARGET_COUNT = 2000  # âš¡ ì‹œì—°ìš©ìœ¼ë¡œ 2,000ê°œë§Œ ë”± í•™ìŠµ! (ì†ë„ ìµœìš°ì„ )

def build_legal_db():
    print("âš–ï¸ ë²•ë ¹ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ 'ë²•ë¥  ë„ì„œê´€'ì„ ì§“ìŠµë‹ˆë‹¤...")
    
    # 1. íŒŒì¼ í™•ì¸
    if not os.path.exists(CSV_PATH):
        # í˜¹ì‹œ ê²½ë¡œê°€ ë‹¤ë¥¼ ê²½ìš° ëŒ€ë¹„
        alt_path = "data/processed/law_database.csv"
        if os.path.exists(alt_path):
            target_path = alt_path
        else:
            print("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    else:
        target_path = CSV_PATH

    # 2. ëª¨ë¸ ì¤€ë¹„ (ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©!)
    print("ğŸš€ ê°€ë²¼ìš´ ì„ë² ë”© ëª¨ë¸(nomic-embed-text) ë¡œë”© ì¤‘...")
    embeddings = OllamaEmbeddings(model="nomic-embed-text")

    # 3. ë°ì´í„° ì½ê¸°
    try:
        print(f"ğŸ“¥ '{target_path}' ì½ëŠ” ì¤‘...")
        df = pd.read_csv(target_path)
        
        # 4. ë°ì´í„° ë‹¤ì´ì–´íŠ¸ (ëœë¤ 2,000ê°œ ì¶”ì¶œ)
        if len(df) > TARGET_COUNT:
            print(f"âœ‚ï¸ ì „ì²´ {len(df)}ê°œ ì¤‘ ëœë¤ìœ¼ë¡œ {TARGET_COUNT}ê°œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. (ì‹œì—°ìš©)")
            df = df.sample(n=TARGET_COUNT, random_state=42) # random_state=42ëŠ” í•­ìƒ ë˜‘ê°™ì€ ëœë¤ì„ ë½‘ê²Œ í•¨
        
        documents = []
        print("ğŸ“„ ë°ì´í„°ë¥¼ ë¬¸ì„œ í˜•íƒœë¡œ ë³€í™˜ ì¤‘...")
        
        for index, row in tqdm(df.iterrows(), total=df.shape[0], desc="Converting"):
            content_parts = []
            for col in df.columns:
                if pd.notna(row[col]):
                    content_parts.append(f"{col}: {row[col]}")
            
            text_content = "\n".join(content_parts)
            documents.append(Document(
                page_content=text_content, 
                metadata={"source": "ë²•ë ¹ë°ì´í„°", "row_id": index}
            ))

        # 5. ë²¡í„° DB ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬)
        print("â³ ë²¡í„° ë³€í™˜ ë° ì €ì¥ ì‹œì‘... (ì•½ 2~3ë¶„ ì†Œìš”)")
        batch_size = 500
        vectorstore = None
        
        for i in tqdm(range(0, len(documents), batch_size), desc="Vectorizing"):
            batch_docs = documents[i : i + batch_size]
            
            if vectorstore is None:
                if os.path.exists(DB_PATH):
                     vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
                     vectorstore.add_documents(batch_docs)
                else:
                    vectorstore = Chroma.from_documents(batch_docs, embeddings, persist_directory=DB_PATH)
            else:
                vectorstore.add_documents(batch_docs)
                
        print(f"âœ… ë²•ë ¹ DB êµ¬ì¶• ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {DB_PATH}")
        print("ğŸ‰ ì´ì œ ëª¨ë“  ì¤€ë¹„ê°€ ëë‚¬ìŠµë‹ˆë‹¤! ì„œë²„(Main)ë¥¼ ë§Œë“¤ëŸ¬ ê°‘ì‹œë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    build_legal_db()