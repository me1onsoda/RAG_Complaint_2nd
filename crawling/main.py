from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import logging

# ìš°ë¦¬ê°€ ë§Œë“  ì „ë¬¸ê°€ë“¤(ëª¨ë“ˆ) ë¶ˆëŸ¬ì˜¤ê¸°
from tool_llama import ComplaintAnalyzer
from department_manager import DepartmentManager
from risk_detector import RiskManager
from legal_advisor import LegalAdvisor

# [ì¶”ê°€] ë¯¼ì› DB ê²€ìƒ‰ìš© (ìœ ì‚¬ ì‚¬ë¡€ ì°¾ê¸°)
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Server")

# 1. FastAPI ì•± ìƒì„± (ì„œë²„ ë³¸ì²´)
app = FastAPI(title="ë¯¼ì› AI í†µí•© ì²˜ë¦¬ ì‹œìŠ¤í…œ", version="1.0")

# 2. ì „ë¬¸ê°€ë“¤ ì¶œê·¼ (ì„œë²„ ì¼¤ ë•Œ í•œ ë²ˆë§Œ ë¡œë”©)
print("ğŸ­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘... (AI ëª¨ë¸ë“¤ì„ ë¡œë”©í•©ë‹ˆë‹¤)")
analyzer = ComplaintAnalyzer()       # ì •ì œ/ìš”ì•½
dept_manager = DepartmentManager()   # ë¶€ì„œ ë°°ì •
risk_manager = RiskManager()         # ìœ„í—˜ íƒì§€
legal_advisor = LegalAdvisor()       # ë²•ë¥  ìë¬¸

# ë¯¼ì› DB ë¡œë”© (ìœ ì‚¬ ì‚¬ë¡€ ì¶”ì²œìš©)
complaint_db = Chroma(
    persist_directory="complaint_vector_db",
    embedding_function=OllamaEmbeddings(model="nomic-embed-text")
)

# == ë°ì´í„° ëª¨ë¸ (ì…ë ¥ë°›ì„ í˜•ì‹) ==
class ComplaintRequest(BaseModel):
    text: str
    location: str = "ë§ˆí¬êµ¬" # ê¸°ë³¸ê°’

# == API ì—”ë“œí¬ì¸íŠ¸ (ê¸°ëŠ¥ ë²„íŠ¼) ==

@app.post("/analyze")
async def process_complaint(request: ComplaintRequest):
    """
    [í†µí•© ì²˜ë¦¬] ë¯¼ì› í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ 5ë‹¨ê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ“© ì‹ ê·œ ë¯¼ì› ì ‘ìˆ˜: {request.text[:20]}...")
    
    response = {
        "original_text": request.text,
        "location": request.location,
        "steps": {}
    }

    # [Step 1] ìœ„í—˜ íƒì§€ (ì•…ì„±/ê¸‰ì¦)
    risk_result = risk_manager.calculate_risk_score(request.text)
    surge_result = risk_manager.check_surge(request.location, "ë¯¸ë¶„ë¥˜") # ì¹´í…Œê³ ë¦¬ëŠ” ì•„ì§ ëª¨ë¦„
    
    response["risk_analysis"] = {
        "is_danger": risk_result["is_danger"],
        "risk_score": risk_result["score"],
        "is_surge": surge_result["is_surge"],
        "tags": []
    }
    if risk_result["is_danger"]: response["risk_analysis"]["tags"].append("ğŸ‘¿ ì•…ì„± ì˜ì‹¬")
    if surge_result["is_surge"]: response["risk_analysis"]["tags"].append("ğŸ”¥ ë¯¼ì› í­ì£¼")

    # [Step 2] ë‚´ìš© ì •ì œ ë° ìš”ì•½ (Llama)
    refined = analyzer.analyze(request.text)
    response["refined_content"] = refined
    
    # [Step 3] ë¶€ì„œ ë°°ì •
    # AIê°€ ë½‘ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì´ìš©í•´ ë¶€ì„œ ë§¤ì¹­
    dept_info = dept_manager.classify_and_match(refined["summary"], request.location)
    response["department_info"] = dept_info

    # [Step 4] ë²•ë¥  ìë¬¸ (RAG)
    # ë¯¼ì› ë‚´ìš©ì´ êµ¬ì²´ì ì¼ ë•Œë§Œ ìë¬¸ ìˆ˜í–‰
    if len(request.text) > 10:
        legal_advice = legal_advisor.advise(refined["summary"])
        response["legal_advice"] = legal_advice
    else:
        response["legal_advice"] = "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ ë²•ë¥  ìë¬¸ì„ ìƒëµí•©ë‹ˆë‹¤."

    # [Step 5] ìœ ì‚¬ ë¯¼ì› ì‚¬ë¡€ ì°¾ê¸° (Bonus)
    docs = complaint_db.similarity_search(refined["summary"], k=2)
    similar_cases = [{"content": d.page_content[:100], "source": d.metadata.get("source")} for d in docs]
    response["similar_cases"] = similar_cases

    return response

# == ì„œë²„ ì‹¤í–‰ ì½”ë“œ ==
if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ ì„œë²„ê°€ 8000ë²ˆ í¬íŠ¸ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤! (http://localhost:8000)")
    uvicorn.run(app, host="0.0.0.0", port=8000)