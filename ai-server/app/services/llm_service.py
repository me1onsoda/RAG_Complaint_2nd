import os
from app import database
from typing import List, Dict, Any
from openai import OpenAI

# [í•„ìˆ˜] OpenAI API Key ì„¤ì •
# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("âš ï¸ ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

client = OpenAI(api_key=OPENAI_API_KEY)


class LLMService:
    def __init__(self):
        # â˜… ìˆ˜ì •ë¨: ëª¨ë¸ëª… ì˜¤íƒ€ ìˆ˜ì • ë° OpenAI ëª¨ë¸ ì§€ì •
        self.embed_model = "text-embedding-3-large"
        # ë¹ ë¥´ê³  ì„±ëŠ¥ ì¢‹ì€ GPT-4o-mini ì‚¬ìš©
        self.chat_model = "gpt-4o-mini"

    async def get_embedding(self, text: str) -> List[float]:
        """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (DBì™€ í˜¸í™˜)"""
        try:
            # ì¤„ë°”ê¿ˆ ì œê±° (OpenAI ê¶Œì¥)
            text = text.replace("\n", " ")

            # â˜… ìˆ˜ì •ë¨: OpenAI API í˜¸ì¶œë¡œ ë³€ê²½
            response = client.embeddings.create(
                input=[text],
                model=self.embed_model,
                dimensions=1024  # DBì™€ ì°¨ì›ìˆ˜ ì¼ì¹˜ í•„ìˆ˜
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ OpenAI ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    async def generate_response(self, complaint_id: int, user_query: str = None, action: str = "chat") -> Dict[
        str, Any]:
        """
        action ì¢…ë¥˜:
         - 'search_law': 'ê´€ë ¨ ê·œì •/ë§¤ë‰´ì–¼ ì°¾ì•„ì¤˜' ë²„íŠ¼ í´ë¦­ ì‹œ
         - 'chat': ì±„íŒ…ì°½ì— ì§ì ‘ ì…ë ¥ ì‹œ
        """

        laws = []

        # 1. DB ê²€ìƒ‰ ë‹¨ê³„ (Actionì— ë”°ë¼ ê²€ìƒ‰ ë°©ì‹ ë¶„ê¸°)
        if action == "search_law":
            print(f"ğŸ” [Button] ë¯¼ì› #{complaint_id} ê´€ë ¨ ë²•ë ¹ ìë™ ê²€ìƒ‰")
            # ë¯¼ì› IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ, ë¯¼ì› ë‚´ìš©ê³¼ ìœ ì‚¬í•œ ë²•ë ¹ì„ DBì—ì„œ ì°¾ìŒ
            laws = database.search_laws_by_id(complaint_id, limit=3)

        else:  # action == 'chat'
            print(f"ğŸ” [Chat] ì‚¬ìš©ì ì§ˆë¬¸ ê²€ìƒ‰: {user_query}")
            # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸(user_query)ì„ ë²¡í„°ë¡œ ë§Œë“¤ì–´ ê²€ìƒ‰
            if user_query:
                vec = await self.get_embedding(user_query)
                if vec:
                    # í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ë™ì‹œì— ìˆ˜í–‰
                    laws = database.search_laws_by_text(vec, limit=3, keyword=user_query)

        # 2. í”„ë¡¬í”„íŠ¸ìš© ì°¸ê³ ìë£Œ í…ìŠ¤íŠ¸ ì¡°ë¦½
        context_text = ""
        if not laws:
            context_text = "(ê²€ìƒ‰ëœ ê´€ë ¨ ë²•ë ¹/ê·œì •ì´ ì—†ìŠµë‹ˆë‹¤.)"
        else:
            for i, law in enumerate(laws, 1):
                # database.pyì—ì„œ ë°˜í™˜í•˜ëŠ” í‚¤ê°’(title, article_no, chunk_text ë“±)ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜´
                title = law.get('title', 'ë²•ë ¹')
                article = law.get('article_no') or law.get('section', '')
                content = law.get('chunk_text') or law.get('content', '')
                context_text += f"[{i}] {title} {article}\n   - ë‚´ìš©: {content[:400]}...\n\n"

        # 3. LLM í˜ë¥´ì†Œë‚˜ ë° í”„ë¡¬í”„íŠ¸ ì„¤ì • (Actionì— ë”°ë¼ ë‹¤ë¥´ê²Œ)
        if action == "search_law":
            # ë²„íŠ¼ í´ë¦­ ì‹œ: ë²•ë ¹ì„ ìš”ì•½í•´ì„œ ì•Œë ¤ì¤Œ
            system_role = "ë‹¹ì‹ ì€ ë¯¼ì› ë²•ë ¹ ê²€ìƒ‰ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. [ì°¸ê³  ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ë¯¼ì›ê³¼ ê´€ë ¨ëœ í•µì‹¬ ê·œì •ì„ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            user_msg = f"ì´ ë¯¼ì›ì„ ì²˜ë¦¬í•  ë•Œ ì°¸ê³ í•´ì•¼ í•  ê´€ë ¨ ë²•ë ¹ì´ë‚˜ ê·œì •ì„ ì•Œë ¤ì¤˜.\n\n[ì°¸ê³  ìë£Œ]:\n{context_text}"

        else:  # chat
            # ì±„íŒ… ì…ë ¥ ì‹œ: ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µì„ ì•Œë ¤ì¤Œ
            system_role = "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ AIì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì•„ë˜ [ì°¸ê³  ìë£Œ]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ê·¼ê±°ê°€ ì—†ë‹¤ë©´ ì—†ë‹¤ê³  ë§í•˜ì„¸ìš”."
            user_msg = f"ì§ˆë¬¸: {user_query}\n\n[ì°¸ê³  ìë£Œ]:\n{context_text}"

        # 4. LLM ë‹µë³€ ìƒì„±
        ai_answer = ""
        try:
            response = client.chat.completions.create(
                model=self.chat_model,
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": user_msg}
                ],
                temperature=0.3  # ì‚¬ì‹¤ê¸°ë°˜ ë‹µë³€ì„ ìœ„í•´ ë‚®ìŒ ìœ ì§€
            )
            ai_answer = response.choices[0].message.content
        except Exception as e:
            ai_answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({str(e)})"

        # 5. ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "answer": ai_answer,
            "documents": laws
        }