import os
import pandas as pd
import psycopg2
from psycopg2.extras import Json
import requests
from datetime import datetime

# --- ì„¤ì • ì„¹ì…˜ ---
DB_CONFIG = {
    "host": "localhost",
    "database": "postgres",
    "user": "postgres",
    "password": "sanghpw",
    "port": 5432
}

OLLAMA_URL = "http://localhost:11434/api/embeddings"
EMBED_MODEL = "mxbai-embed-large"
base_path = os.path.dirname(os.path.abspath(__file__))
CSV_FILE = os.path.join(base_path, "ê°•ë™êµ¬_structured_final.csv")
TABLE_NAME = "complaint_normalizations"

def get_embedding(text):
    # mxbai ëª¨ë¸ ê¶Œì¥ ì ‘ë‘ì‚¬ í¬í•¨
    payload = {"model": EMBED_MODEL, "prompt": f"doc: {text}"}
    try:
        res = requests.post(OLLAMA_URL, json=payload, timeout=10) # íƒ€ì„ì•„ì›ƒ ì¶”ê°€
        return res.json()['embedding']
    except Exception as e:
        print(f"Embedding Error: {e}")
        return None

def migrate_data():
    # 1. íŒŒì¼ ì½ê¸° (ì¸ì½”ë”© ì—ëŸ¬ ë°©ì§€)
    try:
        df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
    except:
        df = pd.read_csv(CSV_FILE, encoding='cp949')

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # 2. ì´ì–´í•˜ê¸° ì§€ì  í™•ì¸ (ì •í™•íˆ ì •ê·œí™” í…Œì´ë¸”ì— ëª‡ ê±´ ìˆëŠ”ì§€ í™•ì¸)
    cur.execute(f"SELECT COUNT(*) FROM {TABLE_NAME}")
    last_count = cur.fetchone()[0]
    
    print(f"í˜„ì¬ DB({TABLE_NAME})ì— ì €ì¥ëœ ë°ì´í„° ìˆ˜: {last_count}ê±´")

    # 3. ë°ì´í„° ìŠ¬ë¼ì´ì‹± (ì´ë¯¸ ì™„ë£Œëœ ê±´ìˆ˜ ì´í›„ë¶€í„° ì‹œì‘)
    # iloc[last_count:] ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì‚½ì… ë°©ì§€
    df_to_process = df.iloc[last_count:]
    
    if len(df_to_process) == 0:
        print("âœ¨ ì´ë¯¸ ëª¨ë“  ë°ì´í„°ê°€ ì´ê´€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸš€ ì´ {len(df)}ê±´ ì¤‘ {last_count}ê±´ ì´í›„ì¸ {len(df_to_process)}ê±´ë¶€í„° ì´ê´€ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    for i, row in df_to_process.iterrows():
        try:
            now = datetime.now()
            
            # 1. ë¶€ëª¨ í…Œì´ë¸” ì‚½ì…
            sql_parent = """
            INSERT INTO complaints (
                received_at, title, body, status, urgency, created_at, updated_at
            ) VALUES (%s, %s, %s, 'RECEIVED', 'MEDIUM', %s, %s) RETURNING id;
            """
            cur.execute(sql_parent, (now, row['req_title'], row['req_p'], now, now))
            new_complaint_id = cur.fetchone()[0]

            # 2. ì„ë² ë”© ìƒì„± (search_text ì»¬ëŸ¼ í™œìš©)
            vector = get_embedding(row['search_text'])
            if not vector:
                print(f"âš ï¸ [{i}] ì„ë² ë”© ì‹¤íŒ¨ - ì´ í–‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                conn.rollback() # ë¶€ëª¨ í…Œì´ë¸” ì‚½ì… ì·¨ì†Œ
                continue

            # 3. ìì‹ í…Œì´ë¸” ì‚½ì…
            sql_child = """
            INSERT INTO complaint_normalizations (
                complaint_id, neutral_summary, core_request, 
                target_object, keywords_jsonb, embedding, resp_dept, is_current
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            keywords_list = [k.strip() for k in str(row['keywords']).split(',')] if pd.notna(row['keywords']) else []
            
            cur.execute(sql_child, (
                new_complaint_id,
                row['search_text'],
                row['topic'],
                row['category'],
                Json(keywords_list),
                vector,
                row['resp_dept'],
                True
            ))

            # 4. ê°œë³„ ê±´ë³„ ì»¤ë°‹ (ì•ˆì •ì„± ìµœìš°ì„ )
            # ì¤‘ê°„ì— êº¼ì ¸ë„ í˜„ì¬ í–‰ê¹Œì§€ëŠ” ì™„ë²½íˆ ì €ì¥ë¨
            conn.commit()
            
            if (i + 1) % 10 == 0 or i == len(df) - 1:
                print(f"âœ… [{i+1}/{len(df)}] ì´ê´€ ì™„ë£Œ (ID: {new_complaint_id})")

        except Exception as e:
            conn.rollback()
            print(f"âŒ Error at row {i}: {e}")
            # ë£¨í”„ë¥¼ ìœ ì§€í• ì§€ ì¤‘ë‹¨í• ì§€ ê²°ì • (ì¼ë‹¨ ì¤‘ë‹¨í•˜ì—¬ ì›ì¸ íŒŒì•… ê¶Œì¥)
            break 

    cur.close()
    conn.close()
    print("âœ¨ ì´ê´€ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")

if __name__ == "__main__":
    migrate_data()