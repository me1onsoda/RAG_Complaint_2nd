from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException
from selenium.webdriver.chrome.options import Options  # ì˜µì…˜ ì„¤ì •ì„ ìœ„í•´ ì¶”ê°€
import re
import time
import pandas as pd
import os


# 1. ê³µê°œ ìƒë‹´ ë¯¼ì› ì¡°íšŒ í˜ì´ì§€ ì´ë™ ë° í•„í„° ì„¤ì •
def move_to_open_minwon(driver):
    driver.execute_script(
        'fnPostLink("/gov/mogaha/ntis/web/emwp/cns/action/EmwpCnslWebAction","selectCnslWebPage","EMWPCnslWebInqL","EmwpCnslWebEJB","selectCnslWebPage","link")')
    time.sleep(2)

    from selenium.webdriver.support.select import Select
    try:
        select_elem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, 'pt_deal_state')))
        select = Select(select_elem)
        select.select_by_value("9")
        driver.execute_script('fncSearch()')
        time.sleep(2)
    except Exception as e:
        print(f"í•„í„° ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")


# 2. ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”
def make_df():
    cols = ['req_id', 'req_title', 'req_p', 'req_date', 'req_content', 'resp_dept', 'resp_date', 'resp_writer',
            'resp_content', 'page_num']
    return pd.DataFrame(columns=cols)


# 3. ë©”ì¸ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
def scrape(driver, district_name, result_df, save_dir):
    wait = WebDriverWait(driver, 15)

    try:
        navi_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'navi')))
        navi_elements[-1].click()
        time.sleep(1)  # [ìˆ˜ì •] 2ì´ˆ -> 1ì´ˆ (ì•ˆì „í•œ ì„ ì—ì„œ ë‹¨ì¶•)
        last_page_num = int(wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'navi')))[-3].text)
        print(f'[{district_name}] ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸: {last_page_num}')

        driver.find_element(By.XPATH, '//*[@id="navigator"]/a[1]').click()
        time.sleep(1)  # [ìˆ˜ì •] 2ì´ˆ -> 1ì´ˆ
    except Exception as e:
        print(f"í˜ì´ì§€ ì •ë³´ íšë“ ì‹¤íŒ¨: {e}")
        return result_df

    while True:
        try:
            wait.until(EC.presence_of_element_located((By.TAG_NAME, 'tbody')))
            spans = driver.find_elements(By.TAG_NAME, 'span')
            page_num = int(spans[-4].text)

            rows = driver.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')
            list_num = len(rows)

            print(f">>> {district_name} - {page_num}í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ (ë¯¼ì› {list_num}ê±´)")

            for i in range(list_num):
                try:
                    wait.until(EC.presence_of_element_located((By.ID, 'dataSetTb')))
                    current_rows = driver.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')
                    transfer_text = current_rows[i].find_element(By.CLASS_NAME, "td-answer").text.strip()
                    target_minwon = current_rows[i].find_element(By.TAG_NAME, 'a')

                    if target_minwon.text.strip() == '':
                        continue

                    driver.execute_script("arguments[0].click();", target_minwon)
                    wait.until(EC.presence_of_element_located((By.TAG_NAME, 'tbody')))
                    tbodies = driver.find_elements(By.TAG_NAME, 'tbody')

                    if 2 <= len(tbodies) <= 3:
                        complaint_table = tbodies[0].find_elements(By.TAG_NAME, 'tr')
                        req_id = complaint_table[0].find_elements(By.TAG_NAME, 'td')[0].text
                        req_title = complaint_table[0].find_elements(By.TAG_NAME, 'td')[-1].text
                        req_p = complaint_table[1].find_elements(By.TAG_NAME, 'td')[0].text
                        req_date = complaint_table[1].find_elements(By.TAG_NAME, 'td')[-2].text
                        req_content = complaint_table[3].find_elements(By.TAG_NAME, 'td')[-1].text
                        req_content = re.split(r'â€» ì²¨ë¶€íŒŒì¼', req_content)[0]

                        resp_dept, resp_date, resp_writer, resp_content = "", "", "", ""

                        if re.search(r'^(ì´ì†¡ì´ì²©|ë‹¤ë¶€ì²˜ë³‘ë ¬)$', transfer_text):
                            try:
                                element = driver.find_element(By.XPATH,
                                                              '/html/body/main/div/table/tbody/tr/td').text.split('\n')
                                resp_dept = re.search(r'\s*:\s*(.+)', element[1]).group(1).strip() if len(
                                    element) > 1 else "Unknown"
                            except:
                                resp_dept = "ì´ì†¡ì´ì²©(ë¶€ì„œí™•ì¸ë¶ˆê°€)"
                        else:
                            resp_table = tbodies[1].find_elements(By.TAG_NAME, 'tr')
                            if len(resp_table) == 3:
                                resp_dept = resp_table[0].find_elements(By.TAG_NAME, 'td')[0].text
                                resp_date = resp_table[0].find_elements(By.TAG_NAME, 'td')[1].text
                                resp_writer = resp_table[1].find_elements(By.TAG_NAME, 'td')[0].text
                                resp_content = resp_table[2].find_elements(By.TAG_NAME, 'td')[0].text
                            else:
                                req_title = "í…ŒìŠ¤íŠ¸"

                        result_df.loc[len(result_df) + 1] = {
                            'req_id': req_id, 'req_title': req_title, 'req_p': req_p,
                            'req_date': req_date, 'req_content': req_content, 'resp_dept': resp_dept,
                            'resp_date': resp_date, 'resp_writer': resp_writer,
                            'resp_content': resp_content, 'page_num': page_num
                        }

                    driver.back()
                    wait.until(EC.presence_of_element_located((By.TAG_NAME, 'tbody')))

                except Exception as row_e:
                    print(f"  - {i + 1}ë²ˆì§¸ í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {row_e}")
                    if len(driver.find_elements(By.ID, 'dataSetTb')) == 0:
                        driver.back()
                    continue

            temp_filename = f'temp_{district_name}.csv'
            temp_path = os.path.join(save_dir, temp_filename)
            result_df.to_csv(temp_path, index=False, encoding='utf-8-sig')

            if page_num == last_page_num:
                break

            next_btn = driver.find_elements(By.CLASS_NAME, 'navi')[-2]
            driver.execute_script("arguments[0].click();", next_btn)
            time.sleep(1)  # [ìˆ˜ì •] 2ì´ˆ -> 1ì´ˆ

        except StaleElementReferenceException:
            print("DOM ë³€ê²½ ê°ì§€ë¨. í˜ì´ì§€ë¥¼ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
            time.sleep(1)  # [ìˆ˜ì •] ì§§ê²Œ ëŒ€ê¸°
            continue
        except Exception as p_e:
            print(f"í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {p_e}")
            break

    return result_df


# 4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì œê±°
def remove_test(result_df):
    try:
        mask = result_df['req_title'].str.contains('í…ŒìŠ¤íŠ¸|test', case=False, na=False)
        result_df = result_df[~mask].reset_index(drop=True)
    except:
        pass
    return result_df


# 5. ì‹¤í–‰ë¶€
url_dict = {
    'ì¤‘ë‘êµ¬': 'https://eminwon.jungnang.go.kr/emwp/gov/mogaha/ntis/web/emwp/cmmpotal/action/EmwpMainMgtAction.do',
}

if __name__ == "__main__":
    current_folder = os.path.dirname(os.path.abspath(__file__))
    save_dir = os.path.join(current_folder, 'data', 'rowdata', 'ìƒˆì˜¬')
    os.makedirs(save_dir, exist_ok=True)

    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {save_dir}")

    # ==========================================
    # ğŸ›¡ï¸ [ì•ˆì „í•œ ì†ë„ í–¥ìƒ ì„¤ì •]
    # ==========================================
    chrome_options = Options()
    # ì´ë¯¸ì§€ ë¡œë”©ë§Œ ë•ë‹ˆë‹¤. (ê°€ì¥ ì•ˆì „í•˜ê³  íš¨ê³¼ì )
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    # ==========================================

    for k, v in url_dict.items():
        print(f'\n############# {k} í¬ë¡¤ë§ ì‹œì‘ #############')

        # ì˜µì…˜ ì ìš©í•´ì„œ ë¸Œë¼ìš°ì € ì—´ê¸°
        driver = webdriver.Chrome(options=chrome_options)

        try:
            driver.get(v)
            move_to_open_minwon(driver)

            initial_df = make_df()
            final_df = scrape(driver, k, initial_df, save_dir)
            final_df = remove_test(final_df)

            final_filename = f'{k}.csv'
            final_path = os.path.join(save_dir, final_filename)

            final_df.to_csv(final_path, index=False, encoding='utf-8-sig')

            temp_filename = f'temp_{k}.csv'
            temp_path = os.path.join(save_dir, temp_filename)

            if os.path.exists(temp_path):
                os.remove(temp_path)

            print(f'############# {k} ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {final_path} #############')
        except Exception as main_e:
            print(f"{k} ì²˜ë¦¬ ì¤‘ ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {main_e}")
        finally:
            driver.quit()