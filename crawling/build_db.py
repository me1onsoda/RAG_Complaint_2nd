import os
import pandas as pd
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œë°”

# ==========================================
# 1. ì„¤ì • (ê²½ë¡œë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
# ==========================================
# ë²¡í„° DBê°€ ì €ì¥ë  í´ë” ì´ë¦„
DB_PATH = "./chroma_db" 

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì •)
FILE_PATHS = {
    "org": "./data/goo_data",          # ì¡°ì§ë„ í´ë”
    "law": "./data/processed",         # ë²•ë ¹ í´ë” (ì´ë¯¸ì§€ìƒ processedì— ë²•ë ¹ì´ ìˆìŒ)
    "complaint": "./data/rowdata"      # ë¯¼ì› ë°ì´í„° í´ë” (ëŒ€ìš©ëŸ‰ ì˜ˆìƒ)
}

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ë¬´ë£Œ, í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸)
# OpenAI í‚¤ ì—†ì´ ë‚´ ì»´í“¨í„° CPU/GPUë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.
print("ğŸ“¥ ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ì²˜ìŒì—” ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ì¢€ ê±¸ë ¤ìš”)")
embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

# ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
vectorstore = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings,
    collection_name="complaint_system" # í•˜ë‚˜ì˜ DB ì•ˆì— ë‹¤ ë‹´ìŠµë‹ˆë‹¤
)

# ==========================================
# 2. ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ==========================================

def process_org_data(folder_path):
    """ì¡°ì§ë„ ë°ì´í„°ë¥¼ ì½ì–´ì„œ í…ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    print(f"\nğŸ¢ ì¡°ì§ë„ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {folder_path}")
    docs = []
    
    for file in os.listdir(folder_path):
        if file.endswith(".csv"):
            full_path = os.path.join(folder_path, file)
            try:
                # ì¸ì½”ë”© ì—ëŸ¬ ë°©ì§€ (cp949 í˜¹ì€ utf-8 ì‹œë„)
                try:
                    df = pd.read_csv(full_path, encoding='utf-8')
                except:
                    df = pd.read_csv(full_path, encoding='cp949')
                
                # ë°ì´í„°í”„ë ˆì„ì„ ëŒë©´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                for _, row in df.iterrows():
                    # ì»¬ëŸ¼ ì´ë¦„ì´ íŒŒì¼ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ëª¨ë“  ì»¬ëŸ¼ì„ í•©ì¹©ë‹ˆë‹¤.
                    # ì˜ˆ: "ë¶€ì„œ: êµí†µê³¼, íŒ€: ê´€ë¦¬íŒ€, ì´ë¦„: í™ê¸¸ë™" ì‹ì˜ ë¬¸ìì—´ ìƒì„±
                    text_content = " | ".join([f"{col}: {val}" for col, val in row.items() if pd.notnull(val)])
                    
                    # ë©”íƒ€ë°ì´í„°(ì¶œì²˜ íŒŒì¼ëª…, íƒ€ì…)
                    metadata = {"source": file, "type": "organization"}
                    
                    docs.append(Document(page_content=text_content, metadata=metadata))
            except Exception as e:
                print(f"âš ï¸ {file} ì½ê¸° ì‹¤íŒ¨: {e}")
                
    return docs

def process_law_data(folder_path):
    """ë²•ë ¹ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    print(f"\nâš–ï¸ ë²•ë ¹ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {folder_path}")
    docs = []
    
    for file in os.listdir(folder_path):
        if "law" in file and file.endswith(".csv"):
            full_path = os.path.join(folder_path, file)
            try:
                try:
                    df = pd.read_csv(full_path, encoding='utf-8')
                except:
                    df = pd.read_csv(full_path, encoding='cp949')
                
                for _, row in df.iterrows():
                    # ë²•ë ¹ì€ ë³´í†µ ë‚´ìš©ì´ ê¸¸ì–´ì„œ ì•ë¶€ë¶„ 1000ìë§Œ ìë¥´ê±°ë‚˜ ê·¸ëŒ€ë¡œ ì”ë‹ˆë‹¤.
                    # rowì— ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•©ì¹©ë‹ˆë‹¤.
                    text_parts = [str(val) for val in row.values if pd.notnull(val)]
                    text_content = " ".join(text_parts)
                    
                    metadata = {"source": file, "type": "law"}
                    docs.append(Document(page_content=text_content, metadata=metadata))
            except Exception as e:
                print(f"âš ï¸ {file} ì½ê¸° ì‹¤íŒ¨: {e}")
    return docs

def save_to_chroma_in_batches(documents, batch_size=100):
    """ë¬¸ì„œë¥¼ ì¡°ê¸ˆì”© ë‚˜ëˆ„ì–´ ì €ì¥í•©ë‹ˆë‹¤ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ í•µì‹¬)"""
    total = len(documents)
    print(f"ğŸ’¾ ì´ {total}ê°œì˜ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤...")
    
    # tqdmìœ¼ë¡œ ì§„í–‰ë¥  ë°” í‘œì‹œ
    for i in tqdm(range(0, total, batch_size), desc="Vectorizing"):
        batch = documents[i : i + batch_size]
        vectorstore.add_documents(batch) # ì—¬ê¸°ì„œ ì‹¤ì œë¡œ ì €ì¥ë¨
        
    print("âœ… ì €ì¥ ì™„ë£Œ!")

# ==========================================
# 3. ì‹¤í–‰ íŒŒíŠ¸
# ==========================================

if __name__ == "__main__":
    # 1. ì¡°ì§ë„ ì²˜ë¦¬
    org_docs = process_org_data(FILE_PATHS["org"])
    if org_docs:
        save_to_chroma_in_batches(org_docs)
    
    # 2. ë²•ë ¹ ì²˜ë¦¬
    law_docs = process_law_data(FILE_PATHS["law"])
    if law_docs:
        save_to_chroma_in_batches(law_docs)
        
    # 3. ë¯¼ì› ë°ì´í„° (ì—¬ê¸°ëŠ” íŒŒì¼ì´ ë„ˆë¬´ í¬ë©´ ë¡œì§ì„ ë”°ë¡œ ì§œì•¼ í•©ë‹ˆë‹¤)
    # ì¼ë‹¨ ì˜ˆì‹œë¡œ law í´ë”ë‚˜ rowdata í´ë”ì— ìˆëŠ” csvë¥¼ ì²˜ë¦¬í•˜ê²Œ ë‘¡ë‹ˆë‹¤.
    # í•„ìš”ì‹œ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ëë‚¬ìŠµë‹ˆë‹¤. 'chroma_db' í´ë”ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")